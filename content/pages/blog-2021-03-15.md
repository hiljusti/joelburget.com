---
layout: post
title: Blog March 15, 2021
category: post
date: 2021-03-15
description: Blog March 15, 2021
permalink: /blog-2021-03-15
listed: True
---

### [A String Diagrammatic Axiomatisation of Finite-State Automata](https://arxiv.org/abs/2009.14576)

> We develop a fully diagrammatic approach to the theory of finite-state automata, based on reinterpreting their usual state-transition graphical representation as a two-dimensional syntax of string diagrams. Moreover, we provide an equational theory that completely axiomatises language equivalence in this new setting. This theory has two notable features. First, the Kleene star is a derived concept, as it can be decomposed into more primitive algebraic blocks. Second, the proposed axiomatisation is finitary — a result which is provably impossible to obtain for the one-dimensional syntax of regular expressions.

> Kleene algebra is not finitely-based: no finite equational theory can appropriately capture the behaviour of the star

> as our most important contribution, we are able to provide a /finite and purely equational/axiomatisation of finite-state automata, up to language equivalence. Intriguingly, this does not contradict the impossibility of finding a finite basis for Kleene algebra, as the algebraic setting is different: our result gives a finite presentation as a symmetric monoidal category, while the impossibility result prevents any such presentation to exist as an algebraic theory (in the standard sense). In other words, there is no finite axiomatisation based on terms (/tree/-like structures), but we demonstrate that there is one based on string diagrams (/graph/-like structures).

### Japan’s Phillips Curve Looks Like Japan

http://www.econ.yale.edu/smith/econ116a/japan.pdf

### [Theoretical models that predict scaling laws - LessWrong](https://www.lesswrong.com/posts/Yt5wAXMc7D2zLpQqx/an-140-theoretical-models-that-predict-scaling-laws#HIGHLIGHTS)

Neat explanation of the manifold hypothesis and scaling laws

### [IQ, trading behavior, and performance](https://www.gwern.net/docs/iq/2012-grinblatt.pdf)

> We analyze whether IQ influences trading behavior, performance, and transaction costs. The analysis combines equity return, trade, and limit order book data with two decades of scores from an intelligence (IQ) test administered to nearly every Finnish male of draft age. Controlling for a variety of factors, we find that high-IQ investors are less subject to the disposition effect, more aggressive about tax-loss trading, and more likely to supply liquidity when stocks experience a one-month high. High-IQ investors also exhibit superior market timing, stock-picking skill, and trade execution.

### [Why did renewables become so cheap so fast? And what can we do to use this global opportunity for green growth? - Our World in Data](https://ourworldindata.org/cheap-renewables-growth)

### [Gauge block - Wikipedia](https://en.wikipedia.org/wiki/Gauge_block)

“Gauge blocks are a system for producing precision lengths”

A few hundred to a few thousand dollars.

> /Wringing/ is the process of sliding two blocks together so that their faces bond. Because of their ultraflat surfaces, when wrung, gauge blocks adhere to each other tightly. Properly wrung blocks may withstand a 300 N (67 lbf) pull. While the exact mechanism that causes wringing is unknown, it is believed to be a combination of:
* air pressure
* surface tension
* molecular attraction

### [Sleep and Sex: What Can Go Wrong? A Review of the Literature on Sleep Related Disorders and Abnormal Sexual Behaviors and Experiences](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1978350/)
> A broad range of sleep related disorders associated with abnormal sexual behaviors and experiences exists, with major clinical and forensic consequences.

### [Right Is The New Left | Slate Star Codex](https://slatestarcodex.com/2014/04/22/right-is-the-new-left/)

> Let’s explain fashion using cellular automata.

### [Case for Aligning Narrowly Superhuman Models](https://www.alignmentforum.org/posts/PZtsoaoSLpKjjbMqM/the-case-for-aligning-narrowly-superhuman-models)

Also, [MIRI comments on “Case for Aligning Narrowly Superhuman Models”](https://www.alignmentforum.org/posts/AyfDnnAdjG7HHeD3d/miri-comments-on-cotra-s-case-for-aligning-narrowly).

Also, [Security Mindset and the Logistic Success Curve](https://intelligence.org/2017/11/26/security-mindset-and-the-logistic-success-curve/)

> There’s often a logistic curve for success probabilities, you know? The distances are measured in multiplicative odds, not additive percentage points. You can’t take a project like this and assume that by putting in some more hard work, you can increase the absolute chance of success by 10%. More like, the odds of this project’s failure versus success start out as 1,000,000:1, and if we’re very polite and navigate around Mr. Topaz’s sense that he is higher-status than us and manage to explain a few tips to him without ever sounding like we think we know something he doesn’t, we can quintuple his chances of success and send the odds to 200,000:1. Which is to say that in the world of percentage points, the odds go from 0.0% to 0.0%. That’s one way to look at the “ [law of continued failure](https://intelligence.org/2017/10/13/fire-alarm) ”.
> If you had the kind of project where the fundamentals implied, say, a 15% chance of success, you’d then be on the right part of the logistic curve, and in /that/ case it could make a lot of sense to hunt for ways to bump that up to a 30% or 80% chance.

### [Agent Incentives: A Causal Perspective](https://arxiv.org/abs/2102.01685)

> We present a framework for analysing agent incentives using causal influence diagrams. We establish that a well-known criterion for value of information is complete. We propose a new graphical criterion for value of control, establishing its soundness and completeness. We also introduce two new concepts for incentive analysis: response incentives indicate which changes in the environment affect an optimal decision, while instrumental control incentives establish whether an agent can influence its utility via a variable X. For both new concepts, we provide sound and complete graphical criteria. We show by example how these results can help with evaluating the safety and fairness of an AI system.

> At this high level, mechanism design is closely related to the incentive design results we have developed in this paper. In practice, the strands of research look rather different. The core challenge of mechanism design is that agents have private information or preferences. As we take the perspective of an agent designer, private information is only relevant for us to the extent that some types of agents or objectives may be harder to implement than others. Instead, our core challenge comes from causal relationships in agent environments, a consideration of little interest to most of mechanism design.
Main concepts: Value of Information, Value of Control, Instrumental Control Incentive, Response Incentive

### Causal Incentives Working Group

> We are a collection of researchers interested in using causal models to understand agent incentives, in order to design safe and fair AI algorithms.
[Papers | Causal Incentives Working Group](https://causalincentives.com)

### [pgmpy: Python Library for learning (Structure and Parameter) and inference (Statistical and Causal) in Bayesian Networks.](https://github.com/pgmpy/pgmpy)

Python library for working with Probabilistic Graphical Models.

Causal games / causal inference notebook: [Google Colaboratory](https://colab.research.google.com/github/pgmpy/pgmpy_notebook/blob/master/notebooks/3.%20Causal%20Bayesian%20Networks.ipynb)

### [How to use hypnagogic hallucinations as biofeedback to relieve insomnia - LessWrong](https://www.lesswrong.com/posts/GwGeksTkFQbm6Hbrx/how-to-use-hypnagogic-hallucinations-as-biofeedback-to)

I've tested this one night so far with little success, but excited to try more.

### [Bathtub curve - Wikipedia](https://en.wikipedia.org/wiki/Bathtub_curve)

The *bathtub curve* is widely used in  [reliability engineering](https://en.wikipedia.org/wiki/Reliability_engineering)  and  [deterioration modeling](https://en.wikipedia.org/wiki/Deterioration_modeling) . It describes a particular form of the  [hazard function](https://en.wikipedia.org/wiki/Hazard_function)  which comprises three parts:
* The first part is a decreasing  [failure rate](https://en.wikipedia.org/wiki/Failure_rate) , known as early  [failures](https://en.wikipedia.org/wiki/Failure) .
* The second part is a constant failure rate, known as  [random](https://en.wikipedia.org/wiki/Random)  failures.
* The third part is an increasing failure rate, known as wear-out failures.

### [dopamine](https://github.com/google/dopamine)

> Dopamine is a research framework for fast prototyping of reinforcement learning algorithms. It aims to fill the need for a small, easily grokked codebase in which users can freely experiment with wild ideas (speculative research).
colabs: [dopamine/README.md at master · google/dopamine · GitHub](https://github.com/google/dopamine/blob/master/dopamine/colab/README.md)

### [Mastering Atari with Discrete World Models](https://arxiv.org/abs/2010.02193)

> Intelligent agents need to generalize from past experience to achieve goals in complex environments. World models facilitate such generalization and allow learning behaviors from imagined outcomes to increase sample-efficiency. While learning world models from image inputs has recently become feasible for some tasks, modeling Atari games accurately enough to derive successful behaviors has remained an open challenge for many years. We introduce DreamerV2, a reinforcement learning agent that learns behaviors purely from predictions in the compact latent space of a powerful world model. The world model uses discrete representations and is trained separately from the policy. DreamerV2 constitutes the first agent that achieves human-level performance on the Atari benchmark of 55 tasks by learning behaviors inside a separately trained world model. With the same computational budget and wall-clock time, DreamerV2 reaches 200M frames and exceeds the final performance of the top single-GPU agents IQN and Rainbow.

### [Epigrams on Programming](https://www.gwern.net/docs/cs/1982-perlis.pdf#page=2)

Alan Perlis (see tweet below)

## Tweets

<Tweet tweetLink="https://twitter.com/ch402/status/1371489233702096897" />
<Tweet tweetLink="https://twitter.com/Austen/status/1370987648957882376" />
<Tweet tweetLink="https://twitter.com/patio11/status/1371005345317851136" />
<Tweet tweetLink="https://twitter.com/viditnanda/status/1370313946545143810" />

<Tweet tweetLink="https://twitter.com/TheRevAlokSingh/status/1370460907201990657" />

<Tweet tweetLink="https://twitter.com/MIRIBerkeley/status/1370053089370255369" />
<Tweet tweetLink="https://twitter.com/robertwiblin/status/1369111651773988864" />
<Tweet tweetLink="https://twitter.com/3xChris/status/1343276717268463617" />
