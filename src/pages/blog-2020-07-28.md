---
layout: post
title: Blog July 28, 2020
category: post
date: 2019-07-28
description: Blog July 28, 2020
permalink: /blog-2020-07-28
listed: True
---

[First Cow Oily Cakes Recipe](https://www.vulture.com/2020/07/first-cow-oily-cakes-recipe.html)

[Benson Log Raft](https://en.wikipedia.org/wiki/Benson_raft)

[Fish ladder](https://en.wikipedia.org/wiki/Fish_ladder)

[zoom.earth](https://zoom.earth/) near real-time satellite images

[Swiss Political System: More than You ever Wanted to Know (I.)](https://www.lesswrong.com/posts/x6hpkYyzMG6Bf8T3W/swiss-political-system-more-than-you-ever-wanted-to-know-i)

[Terry Tao on good math notation](https://mathoverflow.net/a/366118/103345)

[Fixing Mass Effect black blobs on modern AMD CPUs](https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/)
- Debugging and fixing a case where newer AMD CPUs cause sever graphical artifacts in Mass Effect

[The case against the import of GPT-3](https://marginalrevolution.com/marginalrevolution/2020/07/the-case-against-the-import-of-gpt-3.html)
  - Two points to look into:
      - ¬†The architecture itself is 3 years old:¬†[https://arxiv.org/abs/1706.03762](https://secure-web.cisco.com/1iYv0aPwZc-5livVlYpj0NHQEJq6JxHJYBnevVjDA-Ia68dCPdc8Nudbcm74MSjRRAVTcdYPRXjc3iHQejtrYRJ9DhoLxMMlkE9NJKtMWGkfxM83JUw2kTisX58Tt5N4C4eknyr8V2hB5Nh99z004XLCGILbSbpv5RRL1HtJ8683zXI0SPzKJMdzoU_SZnt4_J0eOGiJ9daNFq-BZrZsgCpzeZ2MT33STEIpyCRYnXcVgbvj0KVF-guYHGZLrhOmymmFC_wAz_gzoWterY-q_CFQ2h26PCtyYyZ9p3j-Mj1qaSBoVZTCnzurtPk3wIdGgC09CK01gTsVXn8zCH8gdPAgsrpL2nYDL10hH9KiFIcfxDJqVx_O-VG8ISiBrBznHmAs7UIk-GvfhNFWclqtOMALWUn7Y5-g9YZyZtbA3HU78hZetRhoJnYm_9rL17Mc4/https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762). It is not an exaggeration to say that GPT-3‚Äôs architecture can be described as ‚Äútake that 2017 paper and make 3 numbers (width, # layers, # heads) much bigger‚Äù. The fact that there hasn‚Äôt been any improvement in architecture in 3 years is quite telling.
      - In the paper itself, the authors clearly say they‚Äôre quite near fundamental limits in being able to train an architecture like this. GPT-3 isn‚Äôt a starting point, it‚Äôs an end-point.

[Spaceship Earth](https://www.hulu.com/movie/spaceship-earth-e3636bb2-0aab-43bf-843c-96a4dde8d9a3)
  - In 1991 a group of countercultural visionaries built an enormous replica of earth‚Äôs ecosystem called Biosphere 2. Their epic adventure is a cautionary tale but also a testament to the power of small groups reimagining the world.

[How segregated is New York¬†City?](https://danielkayhertz.com/2014/04/14/how-segregated-is-new-york-city/)
  - (pretty segregated)

[AI poetry, GPT-3 and Predictive¬†Processing](https://besideslife.home.blog/2020/07/25/forays-ai-poetry-gpt-3-and-predictive-processing)
  - [Reddit comments](https://www.reddit.com/r/slatestarcodex/comments/hy1roo/gpt3_and_predictive_processing_theory_of_the_brain/)

[Walking excavator](https://youtu.be/wm0bO-Szfn8) looks like it's from Star Wars

[Food packer machine](https://www.core77.com/posts/100762/Fascinating-Design-for-a-Machine-That-Helps-Food-Packagers-Hit-Target-Weights-for-Multiple-Items)
  - helps to pack e.g. fruit and vegetables with a target weight

[Are we in an AI Overhang?](https://www.lesswrong.com/posts/N6vZEnCn6A95Xn39p/are-we-in-an-ai-overhang) #lesswrong
  - There exists the possibility, today, for *much* more compute to be thrown at a problem
  - "With the naive architecture, increasing the sequence length is quadratically expensive"
  - "In all, tech investment as it is today plausibly supports another 100x-1000x scale up in the very-near-term."

## Tweet section

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;We sort of had to collectively admit we were wrong on the premise that you will be happiest if you work on something you personally want to work on the most,&quot; perhaps valve is not the best example after all <a href="https://t.co/qAb85toRwg">https://t.co/qAb85toRwg</a> (discussion: <a href="https://t.co/7EdK2zzR8y">https://t.co/7EdK2zzR8y</a>)</p>&mdash; Alexey Guzey (@alexeyguzey) <a href="https://twitter.com/alexeyguzey/status/1281471415515058181?ref_src=twsrc%5Etfw">July 10, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Under COVID lockdown and related dramas, my quality of life, looking at life holistically--health, family/friends, work, intellectual life, and summing good with bad--is:</p>&mdash; Antonio Garc√≠a Mart√≠nez (@antoniogm) <a href="https://twitter.com/antoniogm/status/1282550810925129728?ref_src=twsrc%5Etfw">July 13, 2020</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">This paper is a gem. The bulk of it is about academic citation practices, yet it reads like a page-turning mystery. With a twist in the tail! <a href="https://t.co/cHT2i5ijrB">https://t.co/cHT2i5ijrB</a><br><br>If the crudest of errors can persist indefinitely, what does it mean for the theory that science self-corrects? <a href="https://t.co/4g3HbjrVI3">pic.twitter.com/4g3HbjrVI3</a></p>&mdash; Arvind Narayanan (@random_walker) <a href="https://twitter.com/random_walker/status/1283420526288019457?ref_src=twsrc%5Etfw">July 15, 2020</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Spent an enjoyable few hours digging into GPT-3, trying to better understand how it works, what the limits are, how it may be improved.<br><br>The paper is here: <a href="https://t.co/pwPhLUUoaM">https://t.co/pwPhLUUoaM</a></p>&mdash; Michael Nielsen (@michael_nielsen) <a href="https://twitter.com/michael_nielsen/status/1284937254666768384?ref_src=twsrc%5Etfw">July 19, 2020</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Once I got nerd sniped badly. Someone said I can&#39;t write a program that prints itself so I wrote one. One by one they picked language features and said I was cheating to use them. I stripped it down to just one loop and arithmetic. (They still complained.) <a href="https://t.co/aWMKJstbs9">https://t.co/aWMKJstbs9</a></p>&mdash; D ‚ê£ a ‚ê£ n ‚ê£ P ‚ê£ i ‚ê£ p ‚ê£ o ‚ê£ n ‚ê£ i (@sigfpe) <a href="https://twitter.com/sigfpe/status/1286107433073438720?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Hot take: temperature, even on a Kelvin scale, is the reciprocal of a natural quantity, not itself a natural quantity.</p>&mdash; davidad üéá (@davidad) <a href="https://twitter.com/davidad/status/1286305322819354624?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The T5 paper has been published in JMLR! üéâ<a href="https://t.co/siX70Y3ro2">https://t.co/siX70Y3ro2</a><br><br>Since I have already talked more than enough about T5, here instead is a thread about the (awesome) process of publishing in JMLR:<br><br>(1/10)</p>&mdash; Colin Raffel (@colinraffel) <a href="https://twitter.com/colinraffel/status/1287571163414224896?ref_src=twsrc%5Etfw">July 27, 2020</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Wow! Di Lavore and Li explain how to make a category of Petri nets that&#39;s a model of linear logic! I consider myself a sort of expert on Petri nets, but I didn&#39;t know this stuff:<a href="https://t.co/BuhVVIGeek">https://t.co/BuhVVIGeek</a><br><br>Great pictures, too. Let me summarize a tiny bit.<br><br>(1/n) <a href="https://t.co/r7HGtnKu0Z">pic.twitter.com/r7HGtnKu0Z</a></p>&mdash; John Carlos Baez (@johncarlosbaez) <a href="https://twitter.com/johncarlosbaez/status/1287787675634634761?ref_src=twsrc%5Etfw">July 27, 2020</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Terry Tao on nearly failing his Generals exams at Princeton:<br><br>&quot;this was the first time I had performed poorly on an exam that I was genuinely interested in performing well in. But it served as an important wake-up call and a turning point in my career&quot;<a href="https://t.co/gWMYLP6U31">https://t.co/gWMYLP6U31</a></p>&mdash; Alex Kontorovich (@AlexKontorovich) <a href="https://twitter.com/AlexKontorovich/status/1287783464717230081?ref_src=twsrc%5Etfw">July 27, 2020</a></blockquote>
