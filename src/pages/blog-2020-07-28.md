---
layout: post
title: Blog July 28, 2020
category: post
date: 2019-07-28
description: Blog July 28, 2020
permalink: /blog-2020-07-28
listed: True
---

[First Cow Oily Cakes Recipe](https://www.vulture.com/2020/07/first-cow-oily-cakes-recipe.html)

[Benson Log Raft](https://en.wikipedia.org/wiki/Benson_raft)

[Fish ladder](https://en.wikipedia.org/wiki/Fish_ladder)

[zoom.earth](https://zoom.earth/) near real-time satellite images

[Swiss Political System: More than You ever Wanted to Know (I.)](https://www.lesswrong.com/posts/x6hpkYyzMG6Bf8T3W/swiss-political-system-more-than-you-ever-wanted-to-know-i)

[Terry Tao on good math notation](https://mathoverflow.net/a/366118/103345)

[Fixing Mass Effect black blobs on modern AMD CPUs](https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/)
- Debugging and fixing a case where newer AMD CPUs cause sever graphical artifacts in Mass Effect

[The case against the import of GPT-3](https://marginalrevolution.com/marginalrevolution/2020/07/the-case-against-the-import-of-gpt-3.html)
  - Two points to look into:
      -  The architecture itself is 3 years old: [https://arxiv.org/abs/1706.03762](https://secure-web.cisco.com/1iYv0aPwZc-5livVlYpj0NHQEJq6JxHJYBnevVjDA-Ia68dCPdc8Nudbcm74MSjRRAVTcdYPRXjc3iHQejtrYRJ9DhoLxMMlkE9NJKtMWGkfxM83JUw2kTisX58Tt5N4C4eknyr8V2hB5Nh99z004XLCGILbSbpv5RRL1HtJ8683zXI0SPzKJMdzoU_SZnt4_J0eOGiJ9daNFq-BZrZsgCpzeZ2MT33STEIpyCRYnXcVgbvj0KVF-guYHGZLrhOmymmFC_wAz_gzoWterY-q_CFQ2h26PCtyYyZ9p3j-Mj1qaSBoVZTCnzurtPk3wIdGgC09CK01gTsVXn8zCH8gdPAgsrpL2nYDL10hH9KiFIcfxDJqVx_O-VG8ISiBrBznHmAs7UIk-GvfhNFWclqtOMALWUn7Y5-g9YZyZtbA3HU78hZetRhoJnYm_9rL17Mc4/https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762). It is not an exaggeration to say that GPT-3’s architecture can be described as “take that 2017 paper and make 3 numbers (width, # layers, # heads) much bigger”. The fact that there hasn’t been any improvement in architecture in 3 years is quite telling.
      - In the paper itself, the authors clearly say they’re quite near fundamental limits in being able to train an architecture like this. GPT-3 isn’t a starting point, it’s an end-point.

[Spaceship Earth](https://www.hulu.com/movie/spaceship-earth-e3636bb2-0aab-43bf-843c-96a4dde8d9a3)
  - In 1991 a group of countercultural visionaries built an enormous replica of earth’s ecosystem called Biosphere 2. Their epic adventure is a cautionary tale but also a testament to the power of small groups reimagining the world.

[How segregated is New York City?](https://danielkayhertz.com/2014/04/14/how-segregated-is-new-york-city/)
  - (pretty segregated)

[AI poetry, GPT-3 and Predictive Processing](https://besideslife.home.blog/2020/07/25/forays-ai-poetry-gpt-3-and-predictive-processing)
  - [Reddit comments](https://www.reddit.com/r/slatestarcodex/comments/hy1roo/gpt3_and_predictive_processing_theory_of_the_brain/)

[Walking excavator](https://youtu.be/wm0bO-Szfn8) looks like it's from Star Wars

[Food packer machine](https://www.core77.com/posts/100762/Fascinating-Design-for-a-Machine-That-Helps-Food-Packagers-Hit-Target-Weights-for-Multiple-Items)
  - helps to pack e.g. fruit and vegetables with a target weight

[Are we in an AI Overhang?](https://www.lesswrong.com/posts/N6vZEnCn6A95Xn39p/are-we-in-an-ai-overhang) #lesswrong
  - There exists the possibility, today, for *much* more compute to be thrown at a problem
  - "With the naive architecture, increasing the sequence length is quadratically expensive"
  - "In all, tech investment as it is today plausibly supports another 100x-1000x scale up in the very-near-term."

## Tweet section

<Tweet tweetLink="alexeyguzey/status/1281471415515058181" />
<Tweet tweetLink="antoniogm/status/1282550810925129728" />
<Tweet tweetLink="random_walker/status/1283420526288019457" />
<Tweet tweetLink="michael_nielsen/status/1284937254666768384" />
<Tweet tweetLink="sigfpe/status/1286107433073438720" />
<Tweet tweetLink="davidad/status/1286305322819354624" />
<Tweet tweetLink="colinraffel/status/1287571163414224896" />
<Tweet tweetLink="johncarlosbaez/status/1287787675634634761" />
<Tweet tweetLink="AlexKontorovich/status/1287783464717230081" />
